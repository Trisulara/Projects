{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Projektarbeit: Malaria Cell Images Dataset** - Vorhersage mit Convolutional Neuronal Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Als Alternative zu Support Vector Machines wurden unterschiedliche Convolutional Neuronal Networks trainiert:\n",
    "1) 2  convolutional layer, 3 fully connected layer, SGD Optimizer und 5 Epochen: 83% <br>\n",
    "2) 2 convolutional layer, 3 fully connected layer, Adam Optimizer und 20 Epochen: 90% <br>\n",
    "3) 3 convolutional layer, 3 fully connected layer, Adam Optimizer und 10 Epochen: 92% <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bibliotheken importieren\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "import glob\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hilfsfunktion zum Padding\n",
    "def pad_img(img, size):\n",
    "    width, height = img.size\n",
    "    aspect_old = img.size[0] / img.size[1]\n",
    "    aspect_new = size[0] / size[1]\n",
    "    aspect_factor = aspect_new / aspect_old\n",
    "    if (aspect_factor > 0.95) & (aspect_factor < 1.05):\n",
    "        return img\n",
    "    elif aspect_factor < 1:\n",
    "        result = Image.new(img.mode, (width, int(width // aspect_factor)), 0)\n",
    "        result.paste(img, (0, ((result.size[1] - img.size[1]) // 2)))\n",
    "        return result\n",
    "    else:\n",
    "        result = Image.new(img.mode, (int(height * aspect_factor), height), 0)\n",
    "        result.paste(img, ((((result.size[0] - img.size[0]) // 2), 0)))\n",
    "        return result\n",
    "\n",
    "#Hilfsfunktion zum Laden und Transformieren der Bilder\n",
    "def transform_image(image, size=None, grayscale=True, padding=False, contrast=1.0):\n",
    "    if (padding == True) & (size != None):\n",
    "        image = pad_img(image, size)\n",
    "    if size != None:\n",
    "         image = image.resize(size)\n",
    "    if grayscale == True:\n",
    "         image = ImageOps.grayscale(image)\n",
    "        \n",
    "    enhancer = ImageEnhance.Contrast(image)\n",
    "    image = enhancer.enhance(contrast)\n",
    "\n",
    "    return np.asarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "10000\n",
      "12000\n",
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "10000\n",
      "12000\n"
     ]
    }
   ],
   "source": [
    "#Skalierung\n",
    "size = (50, 50)\n",
    "#Padding ja / nein?\n",
    "padding = False\n",
    "#Graustufen ja / nein?\n",
    "grey=False\n",
    "#Kontrast\n",
    "contrast = 1\n",
    "\n",
    "\n",
    "\n",
    "# Bilder mit Label 'parasitized' importieren\n",
    "labels = []\n",
    "imgs = []\n",
    "filelist = glob.glob('Parasitized/*.png')\n",
    "for idx, i in enumerate(filelist):\n",
    "    tmp_image = Image.open(i)\n",
    "    imgs.append(transform_image(tmp_image, size=size, grayscale=grey, padding=padding, contrast=contrast))\n",
    "    tmp_image.close()\n",
    "    labels.append(1)\n",
    "    if(idx % 2000 == 0):\n",
    "        print(idx)\n",
    "          \n",
    "# Bilder mit Label 'uninfected' importieren\n",
    "filelist = glob.glob('Uninfected/*.png')\n",
    "for idx, i in enumerate(filelist):\n",
    "    tmp_image = Image.open(i)\n",
    "    imgs.append(transform_image(tmp_image, size=size, grayscale=grey, padding=padding, contrast=contrast))\n",
    "    tmp_image.close()\n",
    "    labels.append(0)\n",
    "    if(idx % 2000 == 0):\n",
    "        print(idx)\n",
    "        \n",
    "y = np.asarray(labels)\n",
    "X = np.asarray(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Array für CNN transformieren\n",
    "width, height = size\n",
    "X = X.reshape(len(X),1, width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daten aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, stratify=y, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22046, 1, 50, 50])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Numpy in Tensor umwandeln\n",
    "train_X_tensor = torch.from_numpy(X_train).float()\n",
    "train_y_tensor = torch.from_numpy(y_train).long()\n",
    "\n",
    "test_X_tensor = torch.from_numpy(X_test).float()\n",
    "test_y_tensor = torch.from_numpy(y_test).long()\n",
    "\n",
    "train_X_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data und Testloader instanziieren\n",
    "trainset = TensorDataset(train_X_tensor, train_y_tensor)\n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "\n",
    "testset = TensorDataset(test_X_tensor, test_y_tensor)\n",
    "testloader = DataLoader(testset, batch_size=len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "#Check, ob Input richtiges Format hat\n",
    "for i, batch in enumerate(trainloader, 0):\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    inputs, labels = batch\n",
    "    print(inputs.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN mit 2. Convolutional Layers aufbauen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zwei Covolutional Layer\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        #Convolutional Layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2)\n",
    "        \n",
    "        #Pooling Layer --> skalieren quasi das Bild\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        #Convolutional Layer\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        #Fully connected Layers (immer am Ende)\n",
    "        self.fc1 = nn.Linear(16 * 10 * 10, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        # print(x.size)\n",
    "        x = x.view(x.size(0), -1)  # ähnlich wie reshape\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "conv_net = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Netzwerk instanziieren\n",
    "net = ConvNet()\n",
    "\n",
    "# Verlustfunktion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimierer\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training mit 2 Layern, SGD Optimizer und 5 Epochen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.703\n",
      "[1,   200] loss: 0.668\n",
      "[1,   300] loss: 0.648\n",
      "[1,   400] loss: 0.639\n",
      "[1,   500] loss: 0.627\n",
      "[1,   600] loss: 0.609\n",
      "[2,   100] loss: 0.593\n",
      "[2,   200] loss: 0.574\n",
      "[2,   300] loss: 0.565\n",
      "[2,   400] loss: 0.561\n",
      "[2,   500] loss: 0.522\n",
      "[2,   600] loss: 0.524\n",
      "[3,   100] loss: 0.509\n",
      "[3,   200] loss: 0.502\n",
      "[3,   300] loss: 0.494\n",
      "[3,   400] loss: 0.483\n",
      "[3,   500] loss: 0.486\n",
      "[3,   600] loss: 0.473\n",
      "[4,   100] loss: 0.448\n",
      "[4,   200] loss: 0.451\n",
      "[4,   300] loss: 0.454\n",
      "[4,   400] loss: 0.440\n",
      "[4,   500] loss: 0.448\n",
      "[4,   600] loss: 0.444\n",
      "[5,   100] loss: 0.426\n",
      "[5,   200] loss: 0.414\n",
      "[5,   300] loss: 0.435\n",
      "[5,   400] loss: 0.400\n",
      "[5,   500] loss: 0.430\n",
      "[5,   600] loss: 0.413\n",
      "[6,   100] loss: 0.404\n",
      "[6,   200] loss: 0.397\n",
      "[6,   300] loss: 0.393\n",
      "[6,   400] loss: 0.383\n",
      "[6,   500] loss: 0.391\n",
      "[6,   600] loss: 0.410\n",
      "[7,   100] loss: 0.379\n",
      "[7,   200] loss: 0.376\n",
      "[7,   300] loss: 0.377\n",
      "[7,   400] loss: 0.387\n",
      "[7,   500] loss: 0.363\n",
      "[7,   600] loss: 0.375\n",
      "[8,   100] loss: 0.344\n",
      "[8,   200] loss: 0.365\n",
      "[8,   300] loss: 0.365\n",
      "[8,   400] loss: 0.361\n",
      "[8,   500] loss: 0.357\n",
      "[8,   600] loss: 0.346\n",
      "[9,   100] loss: 0.340\n",
      "[9,   200] loss: 0.344\n",
      "[9,   300] loss: 0.362\n",
      "[9,   400] loss: 0.348\n",
      "[9,   500] loss: 0.343\n",
      "[9,   600] loss: 0.326\n",
      "[10,   100] loss: 0.334\n",
      "[10,   200] loss: 0.327\n",
      "[10,   300] loss: 0.330\n",
      "[10,   400] loss: 0.335\n",
      "[10,   500] loss: 0.319\n",
      "[10,   600] loss: 0.335\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, batch in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = batch\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ### forward + backward + optimize\n",
    "\n",
    "        # forward - Vorhersage\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "\n",
    "        # optimize\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # print every 100 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 83 %\n"
     ]
    }
   ],
   "source": [
    "#Accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training mit 2 Layern, Adam Optimizer und 20 Epochen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.073\n",
      "[1,   200] loss: 0.688\n",
      "[1,   300] loss: 0.682\n",
      "[1,   400] loss: 0.679\n",
      "[1,   500] loss: 0.685\n",
      "[1,   600] loss: 0.677\n",
      "[2,   100] loss: 0.672\n",
      "[2,   200] loss: 0.675\n",
      "[2,   300] loss: 0.668\n",
      "[2,   400] loss: 0.673\n",
      "[2,   500] loss: 0.670\n",
      "[2,   600] loss: 0.662\n",
      "[3,   100] loss: 0.674\n",
      "[3,   200] loss: 0.670\n",
      "[3,   300] loss: 0.655\n",
      "[3,   400] loss: 0.650\n",
      "[3,   500] loss: 0.649\n",
      "[3,   600] loss: 0.656\n",
      "[4,   100] loss: 0.645\n",
      "[4,   200] loss: 0.642\n",
      "[4,   300] loss: 0.634\n",
      "[4,   400] loss: 0.553\n",
      "[4,   500] loss: 0.496\n",
      "[4,   600] loss: 0.474\n",
      "[5,   100] loss: 0.422\n",
      "[5,   200] loss: 0.411\n",
      "[5,   300] loss: 0.384\n",
      "[5,   400] loss: 0.383\n",
      "[5,   500] loss: 0.380\n",
      "[5,   600] loss: 0.349\n",
      "[6,   100] loss: 0.293\n",
      "[6,   200] loss: 0.309\n",
      "[6,   300] loss: 0.327\n",
      "[6,   400] loss: 0.301\n",
      "[6,   500] loss: 0.285\n",
      "[6,   600] loss: 0.303\n",
      "[7,   100] loss: 0.250\n",
      "[7,   200] loss: 0.231\n",
      "[7,   300] loss: 0.247\n",
      "[7,   400] loss: 0.264\n",
      "[7,   500] loss: 0.238\n",
      "[7,   600] loss: 0.243\n",
      "[8,   100] loss: 0.192\n",
      "[8,   200] loss: 0.202\n",
      "[8,   300] loss: 0.205\n",
      "[8,   400] loss: 0.205\n",
      "[8,   500] loss: 0.197\n",
      "[8,   600] loss: 0.220\n",
      "[9,   100] loss: 0.158\n",
      "[9,   200] loss: 0.158\n",
      "[9,   300] loss: 0.179\n",
      "[9,   400] loss: 0.161\n",
      "[9,   500] loss: 0.181\n",
      "[9,   600] loss: 0.174\n",
      "[10,   100] loss: 0.127\n",
      "[10,   200] loss: 0.135\n",
      "[10,   300] loss: 0.138\n",
      "[10,   400] loss: 0.152\n",
      "[10,   500] loss: 0.157\n",
      "[10,   600] loss: 0.160\n",
      "[11,   100] loss: 0.112\n",
      "[11,   200] loss: 0.129\n",
      "[11,   300] loss: 0.118\n",
      "[11,   400] loss: 0.137\n",
      "[11,   500] loss: 0.141\n",
      "[11,   600] loss: 0.128\n",
      "[12,   100] loss: 0.092\n",
      "[12,   200] loss: 0.093\n",
      "[12,   300] loss: 0.114\n",
      "[12,   400] loss: 0.108\n",
      "[12,   500] loss: 0.108\n",
      "[12,   600] loss: 0.120\n",
      "[13,   100] loss: 0.078\n",
      "[13,   200] loss: 0.084\n",
      "[13,   300] loss: 0.096\n",
      "[13,   400] loss: 0.090\n",
      "[13,   500] loss: 0.103\n",
      "[13,   600] loss: 0.101\n",
      "[14,   100] loss: 0.078\n",
      "[14,   200] loss: 0.090\n",
      "[14,   300] loss: 0.088\n",
      "[14,   400] loss: 0.067\n",
      "[14,   500] loss: 0.098\n",
      "[14,   600] loss: 0.117\n",
      "[15,   100] loss: 0.050\n",
      "[15,   200] loss: 0.071\n",
      "[15,   300] loss: 0.073\n",
      "[15,   400] loss: 0.061\n",
      "[15,   500] loss: 0.088\n",
      "[15,   600] loss: 0.074\n",
      "[16,   100] loss: 0.041\n",
      "[16,   200] loss: 0.056\n",
      "[16,   300] loss: 0.073\n",
      "[16,   400] loss: 0.085\n",
      "[16,   500] loss: 0.065\n",
      "[16,   600] loss: 0.069\n",
      "[17,   100] loss: 0.039\n",
      "[17,   200] loss: 0.058\n",
      "[17,   300] loss: 0.062\n",
      "[17,   400] loss: 0.088\n",
      "[17,   500] loss: 0.074\n",
      "[17,   600] loss: 0.060\n",
      "[18,   100] loss: 0.048\n",
      "[18,   200] loss: 0.040\n",
      "[18,   300] loss: 0.066\n",
      "[18,   400] loss: 0.051\n",
      "[18,   500] loss: 0.063\n",
      "[18,   600] loss: 0.052\n",
      "[19,   100] loss: 0.035\n",
      "[19,   200] loss: 0.042\n",
      "[19,   300] loss: 0.038\n",
      "[19,   400] loss: 0.033\n",
      "[19,   500] loss: 0.056\n",
      "[19,   600] loss: 0.069\n",
      "[20,   100] loss: 0.044\n",
      "[20,   200] loss: 0.031\n",
      "[20,   300] loss: 0.026\n",
      "[20,   400] loss: 0.030\n",
      "[20,   500] loss: 0.039\n",
      "[20,   600] loss: 0.053\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, batch in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = batch\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ### forward + backward + optimize\n",
    "\n",
    "        # forward - Vorhersage\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "\n",
    "        # optimize\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # print every 100 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 90 %\n"
     ]
    }
   ],
   "source": [
    "#Accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training mit 3 Layern, Adam Optimizer und 10 Epochen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drei Convolutional Layer\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        #1. Convolutional Layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2)\n",
    "        \n",
    "        #Pooling Layer --> skalieren quasi das Bild\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        #2. Convolutional Layer\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, padding=2)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "              \n",
    "        #3. Convolutional Layer\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=24, kernel_size=5, padding=2)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        #Fully connected Layers (immer am Ende)\n",
    "        self.fc1 = nn.Linear(24 * 6 * 6, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        # print(x.size)\n",
    "        x = x.view(x.size(0), -1)  # ähnlich wie reshape\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "conv_net = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Netzwerk instanziieren\n",
    "net = ConvNet()\n",
    "\n",
    "# Verlustfunktion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimierer\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.149\n",
      "[1,   200] loss: 0.181\n",
      "[1,   300] loss: 0.164\n",
      "[1,   400] loss: 0.155\n",
      "[1,   500] loss: 0.161\n",
      "[1,   600] loss: 0.165\n",
      "[2,   100] loss: 0.137\n",
      "[2,   200] loss: 0.146\n",
      "[2,   300] loss: 0.148\n",
      "[2,   400] loss: 0.158\n",
      "[2,   500] loss: 0.155\n",
      "[2,   600] loss: 0.147\n",
      "[3,   100] loss: 0.129\n",
      "[3,   200] loss: 0.118\n",
      "[3,   300] loss: 0.139\n",
      "[3,   400] loss: 0.122\n",
      "[3,   500] loss: 0.137\n",
      "[3,   600] loss: 0.133\n",
      "[4,   100] loss: 0.106\n",
      "[4,   200] loss: 0.107\n",
      "[4,   300] loss: 0.124\n",
      "[4,   400] loss: 0.120\n",
      "[4,   500] loss: 0.139\n",
      "[4,   600] loss: 0.129\n",
      "[5,   100] loss: 0.100\n",
      "[5,   200] loss: 0.109\n",
      "[5,   300] loss: 0.122\n",
      "[5,   400] loss: 0.092\n",
      "[5,   500] loss: 0.106\n",
      "[5,   600] loss: 0.128\n",
      "[6,   100] loss: 0.077\n",
      "[6,   200] loss: 0.095\n",
      "[6,   300] loss: 0.092\n",
      "[6,   400] loss: 0.093\n",
      "[6,   500] loss: 0.110\n",
      "[6,   600] loss: 0.099\n",
      "[7,   100] loss: 0.085\n",
      "[7,   200] loss: 0.083\n",
      "[7,   300] loss: 0.070\n",
      "[7,   400] loss: 0.094\n",
      "[7,   500] loss: 0.073\n",
      "[7,   600] loss: 0.086\n",
      "[8,   100] loss: 0.054\n",
      "[8,   200] loss: 0.085\n",
      "[8,   300] loss: 0.069\n",
      "[8,   400] loss: 0.063\n",
      "[8,   500] loss: 0.080\n",
      "[8,   600] loss: 0.089\n",
      "[9,   100] loss: 0.057\n",
      "[9,   200] loss: 0.064\n",
      "[9,   300] loss: 0.060\n",
      "[9,   400] loss: 0.053\n",
      "[9,   500] loss: 0.054\n",
      "[9,   600] loss: 0.062\n",
      "[10,   100] loss: 0.082\n",
      "[10,   200] loss: 0.050\n",
      "[10,   300] loss: 0.048\n",
      "[10,   400] loss: 0.064\n",
      "[10,   500] loss: 0.071\n",
      "[10,   600] loss: 0.067\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, batch in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = batch\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ### forward + backward + optimize\n",
    "\n",
    "        # forward - Vorhersage\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "\n",
    "        # optimize\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # print every 100 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 92 %\n"
     ]
    }
   ],
   "source": [
    "#Accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
